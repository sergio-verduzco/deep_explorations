{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e72cd6-4d0d-4dd9-a049-b235a1026609",
   "metadata": {},
   "source": [
    "# variational.ipynb\n",
    "A variational autoenconder writing the loss function from Eq. (7) in   \n",
    "[Doersch 2016, Tutorial on Variational Autoencoders](https://arxiv.org/pdf/1606.05908.pdf)\n",
    "\n",
    "\n",
    "-Sergio Verduzco  \n",
    "June 2023\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8250b-a8e9-46be-9983-eafca26ae91c",
   "metadata": {},
   "source": [
    "### Some resources I consulted:\n",
    "https://youtu.be/uaaqyVS9-rM  \n",
    "https://www.youtube.com/watch?v=YV9D3TWY5Zo  \n",
    "https://www.youtube.com/watch?v=8wrLjnQ7EWQ  \n",
    "https://www.youtube.com/watch?v=VELQT1-hILo  \n",
    "https://github.com/karpathy/examples/blob/master/vae/main.py  \n",
    "https://arxiv.org/pdf/1906.02691.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3813c5-1e28-4c62-bac4-2ccba7fb6951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c6cf96-4925-4352-a104-6b9e57498600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Preliminary parameters\n",
    "data_dir = '/home/z/Downloads/data/'  \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device = {device}\")\n",
    "batch_size = 64\n",
    "dataset = 'MNIST'  # MNIST. CIFAR10 not implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5f6263-78bf-48fc-9d9a-4be4e3787d5d",
   "metadata": {},
   "source": [
    "Tricky things with the cell above:\n",
    "* Batch size\n",
    "\n",
    "\n",
    "Tricky things with the cell below:\n",
    "* Which normalization value to use?\n",
    "  * Must ensure it is consistent with the output nonlinearity of the decoder\n",
    "  * Turns out `ToTensor` sets the values between 0 and 1, and this is enough. Further normalizing may hurt performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af30407f-1787-4a5e-aea2-6f97e4c84613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/z/Downloads/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/z/Downloads/data/MNIST/raw/train-images-idx3-ubyte.gz to /home/z/Downloads/data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/z/Downloads/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/z/Downloads/data/MNIST/raw/train-labels-idx1-ubyte.gz to /home/z/Downloads/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/z/Downloads/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/z/Downloads/data/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/z/Downloads/data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/z/Downloads/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /home/z/Downloads/data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/z/Downloads/data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'CIFAR10':  # ignore!\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
    "    #testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "elif dataset == 'MNIST':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         #transforms.Normalize((1.), (0.5)),\n",
    "         torch.squeeze])\n",
    "    trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    #testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "else:\n",
    "    raise ValueError(\"Specify a valid dataset\")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "# testloader = torch.utils.data.DataLoader(testset,\n",
    "#                                          batch_size=batch_size,\n",
    "#                                          shuffle=False,\n",
    "#                                          num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a7ce76-907c-42a0-881d-73fcd874f1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFP(nn.Module):\n",
    "    \"\"\" A feedforward perceptron. \"\"\"\n",
    "    def __init__(self, sizes, nltypes, bias=True):\n",
    "        \"\"\"\n",
    "            sizes: list with size of each layer.\n",
    "            nltypes: list with nonlinearity type for each inner or\n",
    "                output layer. Entries are 'relu', 'sig', or 'tanh'.\n",
    "            bias: whether the layers have a bias unit\n",
    "        \"\"\"\n",
    "        assert len(sizes)-1 == len(nltypes), \"length mismatch in nltypes, sizes\"\n",
    "        super(FFP, self).__init__()\n",
    "        # Add activation functions\n",
    "        self.nlfs = []\n",
    "        for nltype in nltypes:\n",
    "            if nltype == \"relu\":\n",
    "                self.nlfs.append(nn.ReLU())\n",
    "            elif nltype == \"sig\":\n",
    "                self.nlfs.append(nn.Sigmoid())\n",
    "            elif nltype == \"tanh\":\n",
    "                self.nlfs.append(nn.Tanh())\n",
    "            elif nltype == \"linear\":\n",
    "                self.nlfs.append(\"linear\")\n",
    "            else:\n",
    "                raise ValueError(f\"unknown nonlinearity {nltype}\")\n",
    "        # create layers\n",
    "        self.bias = bias\n",
    "        self.sizes = sizes\n",
    "        layers = []\n",
    "        for lidx in range(1,len(sizes)):\n",
    "            layers.append(nn.Linear(sizes[lidx-1], sizes[lidx], bias=bias))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for lidx, layer in enumerate(self.layers):\n",
    "            if self.nlfs[lidx] == \"linear\":\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = self.nlfs[lidx](layer(x))\n",
    "        return x\n",
    "\n",
    "class normal_encoder(nn.Module):\n",
    "    \"\"\" A FFP that outputs parameters for a multivariate normal distribution.\n",
    "    \n",
    "        This is the same as the FFP class, except that the output layer is\n",
    "        duplicated by concatenating an extra set of units with sigmoidal \n",
    "        activation functions. This extra set of units corresponds to the\n",
    "        entries of a diagonal covariance matrix, whereas the regular outputs\n",
    "        corresponds to the means.\n",
    "    \"\"\"\n",
    "    def __init__(self, sizes, nltypes, bias=True):\n",
    "        \"\"\"\n",
    "            sizes: list with size of each layer.\n",
    "            nltypes: list with nonlinearity type for each inner or\n",
    "                output layer. Entries are 'relu', 'sig', 'tanh', or 'linear'.\n",
    "            bias: whether the layers have a bias unit\n",
    "        \"\"\"\n",
    "        assert len(sizes)-1 == len(nltypes), \"length mismatch in nltypes, sizes\"\n",
    "        super(normal_encoder, self).__init__()\n",
    "        self.n_layers = len(nltypes)\n",
    "        # Add activation functions\n",
    "        self.nlfs = []\n",
    "        for nltype in nltypes:\n",
    "            if nltype == \"relu\":\n",
    "                self.nlfs.append(nn.ReLU())\n",
    "            elif nltype == \"sig\":\n",
    "                self.nlfs.append(nn.Sigmoid())\n",
    "            elif nltype == \"tanh\":\n",
    "                self.nlfs.append(nn.Tanh())\n",
    "            elif nltype == \"linear\":\n",
    "                self.nlfs.append(\"linear\")\n",
    "            else:\n",
    "                raise ValueError(f\"unknown nonlinearity {nltype}\")\n",
    "        # create layers\n",
    "        self.bias = bias\n",
    "        self.sizes = sizes\n",
    "        layers = []\n",
    "        for lidx in range(1,len(sizes)):\n",
    "            layers.append(nn.Linear(sizes[lidx-1], sizes[lidx], bias=bias))\n",
    "        # the last element in layers will be the sigmoidal variance layer\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1], bias=bias))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        for lidx, layer in enumerate(self.layers[:-1]):\n",
    "            if lidx == self.n_layers - 1:\n",
    "                y = nn.Sigmoid()(self.layers[-1](x))\n",
    "            if self.nlfs[lidx] == \"linear\":\n",
    "                x = layer(x)\n",
    "            else:\n",
    "                x = self.nlfs[lidx](layer(x))\n",
    "        return torch.concatenate((x, y), axis=-1)\n",
    "        \n",
    "class standard_SGD():\n",
    "    \"\"\" An SGD optimizer for my FFP module. \"\"\"\n",
    "    def __init__(self, model, lr=0.1):\n",
    "        \"\"\"\n",
    "            model: an instance of the FFP class\n",
    "            lr: learning rate\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\" Updates the model's parameters. \"\"\"\n",
    "        for lidx, layer in enumerate(self.model.layers, 1):\n",
    "            dw = self.lr * layer.weight.grad\n",
    "            with torch.no_grad():\n",
    "                layer.weight -= dw\n",
    "                if self.model.bias:\n",
    "                    layer.bias -= self.lr * layer.bias.grad\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for layer in self.model.layers:\n",
    "            layer.weight.grad.zero_()\n",
    "            if self.model.bias:\n",
    "                layer.bias.grad.zero_()\n",
    "\n",
    "def KL_Loss(mu:torch.tensor, sigma:torch.tensor, reduction='mean') -> float:\n",
    "    \"\"\" Encoder loss from the KL divergence.\n",
    "\n",
    "        The loss is the KL divergence between two multivariate\n",
    "        normals. The first has the given means, and a diagonal \n",
    "        variance matrix with the given sigma values. The second\n",
    "        is a multivariate normal zero mean and identity covariance\n",
    "        matrix.\n",
    "\n",
    "        One term that is not relevant for the computation of gradients\n",
    "        is removed from the loss (-k).\n",
    "        \n",
    "        Args:\n",
    "            mu: mean values, size (m,k), where m=minibatch size, k=dimension\n",
    "            sigma: variances, size (m,k)\n",
    "                   All values must be positive.\n",
    "            reduction: 'mean', 'sum', or None\n",
    "        Returns:\n",
    "            loss: KL divergence\n",
    "    \"\"\"\n",
    "    loss =  0.5 * (sigma.sum(axis=1) + (mu * mu).sum(axis=1) - sigma.prod(axis=1).log())\n",
    "    \n",
    "    if loss.dim() == 0:\n",
    "        return loss\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    if reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    if reduction == None:\n",
    "        return loss\n",
    "    raise ValueError(\"type of reduction was not understood.\")\n",
    "\n",
    "def distro_loss(mu:torch.tensor, sigma:torch.tensor, reduction='mean') -> float:\n",
    "    \"\"\" A MSE loss on the paramters of the multivariate normal.\n",
    "    \n",
    "    Args:\n",
    "            mu: mean values, size (m,k), where m=minibatch size, k=dimension\n",
    "            sigma: variances, size (m,k)\n",
    "                   All values must be positive.\n",
    "            reduction: 'mean', 'sum', or None\n",
    "        Returns:\n",
    "            norm of mu plus norm of (sigma - 1)\n",
    "    \"\"\"\n",
    "    loss = (mu * mu).sum() + (sigma - 1).pow(2)\n",
    "\n",
    "    if loss.dim() == 0:\n",
    "        return loss\n",
    "    if reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    if reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    if reduction == None:\n",
    "        return loss\n",
    "    raise ValueError(\"type of reduction was not understood.\")\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593c9df-4d21-403b-a94c-4406f40278ad",
   "metadata": {},
   "source": [
    "Things that caused trouble with the cell above:\n",
    "* Handling the separation in the last encoder layer. Half the outputs are mu, half are sigma.\n",
    "* Ensuring that the sigma values of the encoder are always positive, and finding the right nonlinearity to use for the mu values.\n",
    "  * The answer is to use sigmoidal activation for sigma, and a linear layer for mu.\n",
    "\n",
    "\n",
    "Things that caused trouble with the cell below:\n",
    "* Size of the network and type of nonlinearity for each layer.\n",
    "  * Last layer of encoder must be able to produce both positive and negative values for mu, but only positive for sigma.\n",
    "  * One video said the last layer of the decoder should use sigmoid units because of the MNIST image encoding. When I was normalizing the input images, nothing worked for me until I used a linear output layer. After I stoped normalizing a sigmoidal was probably better.\n",
    "* Optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0eafbd-8cec-41a0-a113-ac5b426f52fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the encoder and decoder\n",
    "enc_sizes = [784, 200, 100, 2]  # 20 means, 20 stds\n",
    "enc_types = ['tanh', 'relu', 'linear']\n",
    "encoder = normal_encoder(enc_sizes, enc_types, bias=True).to(device)\n",
    "\n",
    "dec_sizes = [2, 100, 200, 784]\n",
    "dec_types = ['tanh', 'relu', 'linear']\n",
    "decoder = FFP(dec_sizes, dec_types, bias=True).to(device)\n",
    "\n",
    "# Multivariate normal\n",
    "assert enc_sizes[-1] == dec_sizes[0], \"Check bottleneck sizes\"\n",
    "n_latent = dec_sizes[0]\n",
    "std_multi_normal = torch.distributions.MultivariateNormal(torch.zeros(n_latent), torch.eye(n_latent))\n",
    "\n",
    "# Optimizers\n",
    "# encoder_optim = standard_SGD(encoder, lr=0.001)\n",
    "# decoder_optim = standard_SGD(decoder, lr=0.001)\n",
    "encoder_optim = torch.optim.Adam(encoder.parameters(), lr=5e-4)\n",
    "decoder_optim = torch.optim.Adam(decoder.parameters(), lr=5e-4)\n",
    "# encoder_optim = torch.optim.SGD(encoder.parameters(), lr=0.1)\n",
    "# decoder_optim = torch.optim.SGD(decoder.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1017f23-ce56-4752-bc85-f95d37eb4300",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "    latent error = 0.002696152776479721 up to example 12736\n",
      "    reconstruction error = 0.0625157281756401 up to example 12736\n",
      "    latent error = 0.00296276668086648 up to example 25536\n",
      "    reconstruction error = 0.05762692540884018 up to example 25536\n",
      "    latent error = 0.003186021000146866 up to example 38336\n",
      "    reconstruction error = 0.055440112948417664 up to example 38336\n",
      "    latent error = 0.003396489890292287 up to example 51136\n",
      "    reconstruction error = 0.054002854973077774 up to example 51136\n",
      "latent error = 0.0035270522348582745 in epoch 0\n",
      "reconstruction error = 0.05316968634724617 in epoch 0\n",
      "w = 0.0014656480634585023\n",
      "----------------------------------------\n",
      "    latent error = 0.00459688063710928 up to example 12736\n",
      "    reconstruction error = 0.04819637909531593 up to example 12736\n",
      "    latent error = 0.004724289756268263 up to example 25536\n",
      "    reconstruction error = 0.04786524921655655 up to example 25536\n",
      "    latent error = 0.00485497061163187 up to example 38336\n",
      "    reconstruction error = 0.04760599508881569 up to example 38336\n",
      "    latent error = 0.004987264517694712 up to example 51136\n",
      "    reconstruction error = 0.04734892398118973 up to example 51136\n",
      "latent error = 0.005071014165878296 in epoch 1\n",
      "reconstruction error = 0.04725637659430504 in epoch 1\n",
      "w = 0.0018613473512232304\n",
      "----------------------------------------\n",
      "    latent error = 0.005831510294228792 up to example 12736\n",
      "    reconstruction error = 0.04660211130976677 up to example 12736\n",
      "    latent error = 0.005936643574386835 up to example 25536\n",
      "    reconstruction error = 0.046236421912908554 up to example 25536\n",
      "    latent error = 0.0060455226339399815 up to example 38336\n",
      "    reconstruction error = 0.04616092890501022 up to example 38336\n",
      "    latent error = 0.006152463611215353 up to example 51136\n",
      "    reconstruction error = 0.04606416076421738 up to example 51136\n",
      "latent error = 0.00622614286839962 in epoch 2\n",
      "reconstruction error = 0.04595717415213585 in epoch 2\n",
      "w = 0.0022340253926813602\n",
      "----------------------------------------\n",
      "    latent error = 0.006911254953593016 up to example 12736\n",
      "    reconstruction error = 0.04562867060303688 up to example 12736\n",
      "    latent error = 0.006992730312049389 up to example 25536\n",
      "    reconstruction error = 0.04553456977009773 up to example 25536\n",
      "    latent error = 0.0070922840386629105 up to example 38336\n",
      "    reconstruction error = 0.04553690552711487 up to example 38336\n",
      "    latent error = 0.007196973077952862 up to example 51136\n",
      "    reconstruction error = 0.045486483722925186 up to example 51136\n",
      "latent error = 0.007261930499225855 in epoch 3\n",
      "reconstruction error = 0.045396286994218826 in epoch 3\n",
      "w = 0.002591725206002593\n",
      "----------------------------------------\n",
      "    latent error = 0.007876750081777573 up to example 12736\n",
      "    reconstruction error = 0.04547422006726265 up to example 12736\n",
      "    latent error = 0.007968761958181858 up to example 25536\n",
      "    reconstruction error = 0.04529239237308502 up to example 25536\n",
      "    latent error = 0.008066587150096893 up to example 38336\n",
      "    reconstruction error = 0.04518449679017067 up to example 38336\n",
      "    latent error = 0.008169316686689854 up to example 51136\n",
      "    reconstruction error = 0.04517379403114319 up to example 51136\n",
      "latent error = 0.008228753693401814 in epoch 4\n",
      "reconstruction error = 0.04506293311715126 in epoch 4\n",
      "w = 0.002937228884547949\n",
      "----------------------------------------\n",
      "    latent error = 0.008797344751656055 up to example 12736\n",
      "    reconstruction error = 0.04517706111073494 up to example 12736\n",
      "    latent error = 0.008883500471711159 up to example 25536\n",
      "    reconstruction error = 0.04499245434999466 up to example 25536\n",
      "    latent error = 0.00898995902389288 up to example 38336\n",
      "    reconstruction error = 0.04485051706433296 up to example 38336\n",
      "    latent error = 0.009072859771549702 up to example 51136\n",
      "    reconstruction error = 0.04489941895008087 up to example 51136\n",
      "latent error = 0.009128350764513016 in epoch 5\n",
      "reconstruction error = 0.04483717679977417 in epoch 5\n",
      "w = 0.0032721776515245438\n",
      "----------------------------------------\n",
      "    latent error = 0.009727728553116322 up to example 12736\n",
      "    reconstruction error = 0.04500161483883858 up to example 12736\n",
      "    latent error = 0.00979857612401247 up to example 25536\n",
      "    reconstruction error = 0.044752851128578186 up to example 25536\n",
      "    latent error = 0.009883408434689045 up to example 38336\n",
      "    reconstruction error = 0.04463007301092148 up to example 38336\n",
      "    latent error = 0.00997199211269617 up to example 51136\n",
      "    reconstruction error = 0.04467898607254028 up to example 51136\n",
      "latent error = 0.010019269771873951 in epoch 6\n",
      "reconstruction error = 0.04463610053062439 in epoch 6\n",
      "w = 0.003596882801502943\n",
      "----------------------------------------\n",
      "    latent error = 0.010586905293166637 up to example 12736\n",
      "    reconstruction error = 0.044962622225284576 up to example 12736\n",
      "    latent error = 0.010648800991475582 up to example 25536\n",
      "    reconstruction error = 0.044763971120119095 up to example 25536\n",
      "    latent error = 0.010713232681155205 up to example 38336\n",
      "    reconstruction error = 0.04468941316008568 up to example 38336\n",
      "    latent error = 0.010805046185851097 up to example 51136\n",
      "    reconstruction error = 0.04462296888232231 up to example 51136\n",
      "latent error = 0.010854454711079597 in epoch 7\n",
      "reconstruction error = 0.04453759640455246 in epoch 7\n",
      "w = 0.003912834450602531\n",
      "----------------------------------------\n",
      "    latent error = 0.011408694088459015 up to example 12736\n",
      "    reconstruction error = 0.04443087428808212 up to example 12736\n",
      "    latent error = 0.011489992029964924 up to example 25536\n",
      "    reconstruction error = 0.04448573291301727 up to example 25536\n",
      "    latent error = 0.011553512886166573 up to example 38336\n",
      "    reconstruction error = 0.04446573927998543 up to example 38336\n",
      "    latent error = 0.011633367277681828 up to example 51136\n",
      "    reconstruction error = 0.04449533298611641 up to example 51136\n",
      "latent error = 0.011680041439831257 in epoch 8\n",
      "reconstruction error = 0.04439089819788933 in epoch 8\n",
      "w = 0.004219664726406336\n",
      "----------------------------------------\n",
      "    latent error = 0.012219456024467945 up to example 12736\n",
      "    reconstruction error = 0.04448818415403366 up to example 12736\n",
      "    latent error = 0.01227657776325941 up to example 25536\n",
      "    reconstruction error = 0.044375229626894 up to example 25536\n",
      "    latent error = 0.012373221106827259 up to example 38336\n",
      "    reconstruction error = 0.04431390389800072 up to example 38336\n",
      "    latent error = 0.012441067956387997 up to example 51136\n",
      "    reconstruction error = 0.044276244938373566 up to example 51136\n",
      "latent error = 0.012466641142964363 in epoch 9\n",
      "reconstruction error = 0.04427829384803772 in epoch 9\n",
      "w = 0.004518056288361549\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_epochs = 10\n",
    "bsize = trainloader.batch_size\n",
    "w_bit = .1 / (n_epochs * (len(trainset) / bsize))\n",
    "w = 0.001\n",
    "for epoch in range(n_epochs):\n",
    "    accum_latent_error = 0.\n",
    "    accum_output_error = 0.\n",
    "    print(\"----------------------------------------\")\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # retrieve the input\n",
    "        input = data[0].flatten(start_dim=1).to(device)  # (bsize, 784)\n",
    "        # feed the input to the encoder\n",
    "        latent = encoder(input)  # (bsize, 2*n_latent)\n",
    "        # extract means and diagonal of variance matrix\n",
    "        means = latent[:, :enc_sizes[-1]]  # (bsize, n_latent)\n",
    "        vars = latent[:, enc_sizes[-1]:]  # (bsize, n_latent)\n",
    "        # sample from the multivariate normal. Size = (bsize, n_latent)\n",
    "        #epsilons = std_multi_normal.sample((bsize,)).to(device)\n",
    "        epsilons = torch.randn_like(vars)\n",
    "        z = means + epsilons * vars\n",
    "        # feed the sample to the decoder\n",
    "        output = decoder(z)\n",
    "        # Gradient descent\n",
    "        # w += w_bit\n",
    "        latent_error = w * KL_Loss(means, vars)\n",
    "        # latent_error = w * distro_loss(means, vars)\n",
    "        output_error = mse_loss(input, output)\n",
    "        #output_error = F.binary_cross_entropy(input, output, reduction='mean')\n",
    "        error = latent_error + output_error\n",
    "        \n",
    "        error.backward()\n",
    "        \n",
    "        encoder_optim.step()\n",
    "        decoder_optim.step()\n",
    "\n",
    "        encoder_optim.zero_grad()\n",
    "        decoder_optim.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w += 1e-5 * (output_error - latent_error)\n",
    "\n",
    "        # display error\n",
    "        accum_latent_error += latent_error\n",
    "        accum_output_error += output_error\n",
    "        if (i+1) % 200 == 0:\n",
    "            print(f\"    latent error = {accum_latent_error/i} up to example {i*bsize}\")\n",
    "            print(f\"    reconstruction error = {accum_output_error/i} up to example {i*bsize}\")\n",
    "    accum_latent_error /= len(trainloader)\n",
    "    accum_output_error /= len(trainloader)\n",
    "    print(f\"latent error = {accum_latent_error} in epoch {epoch}\")\n",
    "    print(f\"reconstruction error = {accum_output_error} in epoch {epoch}\")\n",
    "    print(f\"w = {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7102a6d-cbca-45a2-b20d-2f695378de8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class image_generator():\n",
    "    def __init__(self, decoder, distribution):\n",
    "        self.decoder = decoder\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def generate(self, show=True):\n",
    "        input = self.distribution.sample().to(device)\n",
    "        \n",
    "        output = decoder(input).reshape((28,28)).to('cpu').detach()\n",
    "        if show:\n",
    "            plt.imshow(output)\n",
    "        return output\n",
    "\n",
    "# empirical_multi_normal = torch.distributions.MultivariateNormal(0.0*torch.ones(n_latent), 0.7*torch.eye(n_latent))\n",
    "# imgen = image_generator(decoder, empirical_multi_normal)\n",
    "\n",
    "imgen = image_generator(decoder, std_multi_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70c3ba7e-46db-4acc-a4de-53b6145a7dd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run repeatedly to get many images\n",
    "val = imgen.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a823af-0ce1-440f-b867-d161b02020de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[28, 28] n=784 (3.1Kb) x∈[-0.073, 1.001] μ=0.123 σ=0.242\n"
     ]
    }
   ],
   "source": [
    "# Test the decoder's statistitics. Should look like the \"input\" next cell\n",
    "print(val)\n",
    "#print(std_multi_normal.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a836279-58bb-4487-ae93-de6d8c8bc769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input =  tensor[1, 784] 3.1Kb x∈[0., 1.000] μ=0.138 σ=0.313 cuda:0\n",
      "mu =  tensor[2] μ=-0.709 σ=0.151 grad SliceBackward0 cuda:0 [-0.602, -0.816]\n",
      "sigma =  tensor[2] μ=0.138 σ=0.041 grad SliceBackward0 cuda:0 [0.109, 0.167]\n",
      "==========================\n",
      "input =  tensor[1, 784] 3.1Kb x∈[0., 1.000] μ=0.156 σ=0.329 cuda:0\n",
      "mu =  tensor[2] μ=0.813 σ=0.997 grad SliceBackward0 cuda:0 [1.518, 0.108]\n",
      "sigma =  tensor[2] μ=0.112 σ=0.026 grad SliceBackward0 cuda:0 [0.093, 0.131]\n",
      "==========================\n",
      "input =  tensor[1, 784] 3.1Kb x∈[0., 1.000] μ=0.097 σ=0.257 cuda:0\n",
      "mu =  tensor[2] μ=-0.096 σ=0.426 grad SliceBackward0 cuda:0 [0.205, -0.397]\n",
      "sigma =  tensor[2] μ=0.084 σ=0.024 grad SliceBackward0 cuda:0 [0.067, 0.101]\n",
      "==========================\n",
      "input =  tensor[1, 784] 3.1Kb x∈[0., 1.000] μ=0.086 σ=0.259 cuda:0\n",
      "mu =  tensor[2] μ=-0.820 σ=1.292 grad SliceBackward0 cuda:0 [-1.734, 0.094]\n",
      "sigma =  tensor[2] μ=0.155 σ=0.004 grad SliceBackward0 cuda:0 [0.158, 0.153]\n",
      "==========================\n",
      "input =  tensor[1, 784] 3.1Kb x∈[0., 1.000] μ=0.116 σ=0.292 cuda:0\n",
      "mu =  tensor[2] μ=0.219 σ=0.422 grad SliceBackward0 cuda:0 [-0.079, 0.518]\n",
      "sigma =  tensor[2] μ=0.089 σ=0.020 grad SliceBackward0 cuda:0 [0.075, 0.102]\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# Test the encoder's output statistics\n",
    "sample_num = 5\n",
    "\n",
    "for n in range(sample_num):\n",
    "    input = trainset[n][0].flatten().reshape(1,-1).to(device)\n",
    "    latent = encoder(input)\n",
    "    mu = latent[0, :n_latent]\n",
    "    sigma = latent[0, n_latent:]\n",
    "    print(\"input = \", end=\" \")\n",
    "    print(input)\n",
    "    print(\"mu = \", end=\" \")\n",
    "    print(mu)\n",
    "    print(\"sigma = \", end=\" \")\n",
    "    print(sigma)\n",
    "    print(\"==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9d3fc33a-8d25-49f1-822b-d7cc67cc8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(decoder.state_dict(), 'decoder_distro_loss01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e223151-02a4-427c-872b-1578f1a1e4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
